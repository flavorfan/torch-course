{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GrEq-257c--s"
   },
   "source": [
    "### 32 Training Loop Run Builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E-LiD6_pqFIY"
   },
   "outputs": [],
   "source": [
    "from collections import OrderedDict, namedtuple\n",
    "from itertools import product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RunBuilder:\n",
    "    @staticmethod\n",
    "    def get_runs(params):\n",
    "\n",
    "        Run = namedtuple('Run', params.keys())\n",
    "\n",
    "        runs = []\n",
    "        for v in product(*params.values()):\n",
    "            runs.append(Run(*v))\n",
    "\n",
    "        return runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [32, 64]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['lr', 'batch_size'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(lr=0.01, batch_size=32),\n",
       " Run(lr=0.01, batch_size=64),\n",
       " Run(lr=0.001, batch_size=32),\n",
       " Run(lr=0.001, batch_size=64)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = RunBuilder.get_runs(params)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Run(lr=0.01, batch_size=32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 32\n"
     ]
    }
   ],
   "source": [
    "print(runs[0].lr, runs[0].batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01 32\n",
      "0.01 64\n",
      "0.001 32\n",
      "0.001 64\n"
     ]
    }
   ],
   "source": [
    "for run in runs:\n",
    "    print(run.lr, run.batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Two parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(lr=0.01, batch_size=32),\n",
       " Run(lr=0.01, batch_size=64),\n",
       " Run(lr=0.001, batch_size=32),\n",
       " Run(lr=0.001, batch_size=64)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [32, 64],\n",
    "\n",
    ")\n",
    "runs = RunBuilder.get_runs(params)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(lr=0.01, batch_size=32, device='cpu'),\n",
       " Run(lr=0.01, batch_size=32, device='cuda'),\n",
       " Run(lr=0.01, batch_size=64, device='cpu'),\n",
       " Run(lr=0.01, batch_size=64, device='cuda'),\n",
       " Run(lr=0.001, batch_size=32, device='cpu'),\n",
       " Run(lr=0.001, batch_size=32, device='cuda'),\n",
       " Run(lr=0.001, batch_size=64, device='cpu'),\n",
       " Run(lr=0.001, batch_size=64, device='cuda')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [0.01, 0.001],\n",
    "    batch_size = [32, 64],\n",
    "    device = ['cpu', 'cuda']\n",
    ")\n",
    "\n",
    "runs = RunBuilder.get_runs(params)\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['lr', 'batch_size', 'device'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_values([[0.01, 0.001], [32, 64], ['cpu', 'cuda']])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Run"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Run = namedtuple('Run', params.keys())\n",
    "Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Run(lr=0.01, batch_size=32, device='cpu'),\n",
       " Run(lr=0.01, batch_size=32, device='cuda'),\n",
       " Run(lr=0.01, batch_size=64, device='cpu'),\n",
       " Run(lr=0.01, batch_size=64, device='cuda'),\n",
       " Run(lr=0.001, batch_size=32, device='cpu'),\n",
       " Run(lr=0.001, batch_size=32, device='cuda'),\n",
       " Run(lr=0.001, batch_size=64, device='cpu'),\n",
       " Run(lr=0.001, batch_size=64, device='cuda')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "runs = []\n",
    "for v in product(*params.values()):\n",
    "    runs.append(Run(*v))\n",
    "runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-Run(lr=0.001, batch_size=64)\n",
      "-Run(lr=0.001, batch_size=64)\n",
      "-Run(lr=0.001, batch_size=64)\n",
      "-Run(lr=0.001, batch_size=64)\n",
      "-Run(lr=0.001, batch_size=64)\n",
      "-Run(lr=0.001, batch_size=64)\n",
      "-Run(lr=0.001, batch_size=64)\n",
      "-Run(lr=0.001, batch_size=64)\n"
     ]
    }
   ],
   "source": [
    "for fun in RunBuilder.get_runs(params):\n",
    "    comment = f'-{run}'\n",
    "\n",
    "    # Training process given the set of parameters\n",
    "    print(comment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 33 CNN Training Loop Refactoring - Simultaneous Hyperparameter Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-02 19:36:26.681440: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1733139386.701830 2233320 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1733139386.708000 2233320 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-12-02 19:36:26.730476: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torchvision\n",
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "class RunManager:\n",
    "    def __init__(self):\n",
    "        self.epoch_count = 0\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "        self.epoch_start_time = None\n",
    "\n",
    "        self.run_params = None\n",
    "        self.run_count = 0\n",
    "        self.run_data = []\n",
    "        self.run_start_time = None\n",
    "\n",
    "        self.model = None\n",
    "        self.loader = None\n",
    "        self.tb = None\n",
    "\n",
    "    def begin_run(self, hyper_params, model, loader):\n",
    "        self.run_start_time = time.time()\n",
    "        self.run_params = hyper_params\n",
    "        self.run_count += 1\n",
    "\n",
    "        self.model = model\n",
    "        self.loader = loader\n",
    "        self.tb = SummaryWriter(comment=f'-{hyper_params}')\n",
    "\n",
    "        images, labels = next(iter(self.loader))\n",
    "        grid = torchvision.utils.make_grid(images)\n",
    "        \n",
    "        self.tb.add_image('images', grid)\n",
    "        self.tb.add_graph(self.model, images)\n",
    "\n",
    "    def end_run(self):\n",
    "        self.tb.close()\n",
    "        self.epoch_count = 0\n",
    "\n",
    "    def begin_epoch(self, epoch_no):\n",
    "        self.epoch_start_time = time.time()\n",
    "\n",
    "        self.epoch_count += 1\n",
    "        self.epoch_loss = 0\n",
    "        self.epoch_num_correct = 0\n",
    "\n",
    "        # print(f\"Epoch {epoch_no} started ...\", end=\" \")\n",
    "\n",
    "    def end_epoch(self):\n",
    "        epoch_duration = time.time() - self.epoch_start_time\n",
    "        run_duration = time.time() - self.run_start_time\n",
    "\n",
    "        loss = self.epoch_loss / len(self.loader.dataset)\n",
    "        accuracy = self.epoch_num_correct / len(self.loader.dataset)\n",
    "\n",
    "        self.tb.add_scalar('Loss', loss, self.epoch_count)\n",
    "        self.tb.add_scalar('Accuracy', accuracy, self.epoch_count)\n",
    "\n",
    "        for name, param in self.model.named_parameters():\n",
    "            self.tb.add_histogram(name, param, self.epoch_count)\n",
    "            self.tb.add_histogram(f'{name}.grad', param.grad, self.epoch_count)\n",
    "\n",
    "        results = OrderedDict()\n",
    "        results[\"run\"] = self.run_count\n",
    "        results[\"epoch\"] = self.epoch_count\n",
    "        results[\"loss\"] = loss\n",
    "        results[\"accuracy\"] = accuracy\n",
    "        results[\"epoch_duration\"] = epoch_duration\n",
    "        results[\"run duration\"] = run_duration\n",
    "\n",
    "        for k, v in self.run_params._asdict().items():\n",
    "            results[k] = v\n",
    "\n",
    "        self.run_data.append(results)\n",
    "        df = pd.DataFrame.from_dict(self.run_data, orient='columns')\n",
    "\n",
    "        clear_output(wait=True)\n",
    "        display(df)\n",
    "        # print(\"Ended\")\n",
    "\n",
    "    def track_loss(self, loss):\n",
    "        self.epoch_loss += loss.item() * self.loader.batch_size\n",
    "\n",
    "    def track_num_correct(self, preds, labels):\n",
    "        self.epoch_num_correct += self._get_num_correct(preds, labels)\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def _get_num_correct(self, preds, labels):\n",
    "        return preds.argmax(dim=1).eq(labels).sum().item()\n",
    "\n",
    "    def save(self, fileName):\n",
    "        pd.DataFrame.from_dict(self.run_data, orient='columns', ).to_csv(f'{fileName}.csv')\n",
    "        with open(f'{fileName}.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(self.run_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1+cu124\n",
      "0.20.1+cu124\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "\n",
    "torch.set_printoptions(linewidth=120)\n",
    "torch.set_grad_enabled(True)\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter # <-- new\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torchvision.__version__)\n",
    "\n",
    "class Network(nn.Module):\n",
    "    def __init__(self, channels=1): # default grayscale\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=channels, out_channels=6, kernel_size=5) \n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120) # ((28-5+1)/2 -5 +1)/2 = 4\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, (2, 2), stride=2)\n",
    "\n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, (2, 2), stride=2)\n",
    "\n",
    "        t = t.reshape(-1, 12*4*4)\n",
    "        t = F.relu(self.fc1(t))\n",
    "\n",
    "        t = F.relu(self.fc2(t))\n",
    "\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST',\n",
    "    download=True,\n",
    "    transform=transform.Compose([\n",
    "        transform.ToTensor()\n",
    "    ]))\n",
    "\n",
    "# train_loader = torch.utils.data.DataLoader(train_set, batch_size=100, shuffle=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.942568</td>\n",
       "      <td>0.641450</td>\n",
       "      <td>8.328573</td>\n",
       "      <td>8.866978</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.479108</td>\n",
       "      <td>0.822633</td>\n",
       "      <td>8.365075</td>\n",
       "      <td>17.380928</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.394044</td>\n",
       "      <td>0.856033</td>\n",
       "      <td>8.501794</td>\n",
       "      <td>26.004044</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.357565</td>\n",
       "      <td>0.869117</td>\n",
       "      <td>8.453928</td>\n",
       "      <td>34.573614</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.336215</td>\n",
       "      <td>0.877050</td>\n",
       "      <td>8.282996</td>\n",
       "      <td>42.974124</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.201559</td>\n",
       "      <td>0.544600</td>\n",
       "      <td>8.301674</td>\n",
       "      <td>9.384692</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.603490</td>\n",
       "      <td>0.764267</td>\n",
       "      <td>8.401149</td>\n",
       "      <td>17.909029</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.508192</td>\n",
       "      <td>0.802950</td>\n",
       "      <td>8.356733</td>\n",
       "      <td>26.389409</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.459300</td>\n",
       "      <td>0.828233</td>\n",
       "      <td>8.414301</td>\n",
       "      <td>34.921250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.421466</td>\n",
       "      <td>0.844983</td>\n",
       "      <td>8.332051</td>\n",
       "      <td>43.375174</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  epoch_duration  run duration    lr  \\\n",
       "0    1      1  0.942568  0.641450        8.328573      8.866978  0.01   \n",
       "1    1      2  0.479108  0.822633        8.365075     17.380928  0.01   \n",
       "2    1      3  0.394044  0.856033        8.501794     26.004044  0.01   \n",
       "3    1      4  0.357565  0.869117        8.453928     34.573614  0.01   \n",
       "4    1      5  0.336215  0.877050        8.282996     42.974124  0.01   \n",
       "5    2      1  1.201559  0.544600        8.301674      9.384692  0.01   \n",
       "6    2      2  0.603490  0.764267        8.401149     17.909029  0.01   \n",
       "7    2      3  0.508192  0.802950        8.356733     26.389409  0.01   \n",
       "8    2      4  0.459300  0.828233        8.414301     34.921250  0.01   \n",
       "9    2      5  0.421466  0.844983        8.332051     43.375174  0.01   \n",
       "\n",
       "   batch_size  \n",
       "0        1000  \n",
       "1        1000  \n",
       "2        1000  \n",
       "3        1000  \n",
       "4        1000  \n",
       "5        2000  \n",
       "6        2000  \n",
       "7        2000  \n",
       "8        2000  \n",
       "9        2000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ended\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "params = OrderedDict(\n",
    "    lr = [.01],\n",
    "    batch_size = [1000, 2000],\n",
    ")\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    network = Network()\n",
    "    loader = DataLoader(train_set, batch_size=run.batch_size) \n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(5):\n",
    "        m.begin_epoch(epoch)\n",
    "\n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "\n",
    "m.save('results')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>shuffle</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.017841</td>\n",
       "      <td>0.612950</td>\n",
       "      <td>7.645893</td>\n",
       "      <td>8.197881</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.521381</td>\n",
       "      <td>0.797317</td>\n",
       "      <td>7.493823</td>\n",
       "      <td>15.809482</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.420959</td>\n",
       "      <td>0.846900</td>\n",
       "      <td>7.524096</td>\n",
       "      <td>23.443556</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.376354</td>\n",
       "      <td>0.861817</td>\n",
       "      <td>7.458082</td>\n",
       "      <td>31.018337</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.343932</td>\n",
       "      <td>0.872367</td>\n",
       "      <td>7.551965</td>\n",
       "      <td>38.690419</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.901488</td>\n",
       "      <td>0.661833</td>\n",
       "      <td>8.522249</td>\n",
       "      <td>9.061235</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.465672</td>\n",
       "      <td>0.826367</td>\n",
       "      <td>8.366937</td>\n",
       "      <td>17.577125</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.386732</td>\n",
       "      <td>0.857750</td>\n",
       "      <td>8.584581</td>\n",
       "      <td>26.274714</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.351575</td>\n",
       "      <td>0.869317</td>\n",
       "      <td>8.387501</td>\n",
       "      <td>34.794836</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.328205</td>\n",
       "      <td>0.878800</td>\n",
       "      <td>8.313120</td>\n",
       "      <td>43.234395</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.277515</td>\n",
       "      <td>0.512050</td>\n",
       "      <td>8.508451</td>\n",
       "      <td>9.625108</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.674211</td>\n",
       "      <td>0.731617</td>\n",
       "      <td>8.462582</td>\n",
       "      <td>18.208171</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.584290</td>\n",
       "      <td>0.771167</td>\n",
       "      <td>8.500220</td>\n",
       "      <td>26.829895</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.522286</td>\n",
       "      <td>0.799667</td>\n",
       "      <td>8.523609</td>\n",
       "      <td>35.475895</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.469065</td>\n",
       "      <td>0.826067</td>\n",
       "      <td>8.506910</td>\n",
       "      <td>44.105716</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.280718</td>\n",
       "      <td>0.512583</td>\n",
       "      <td>8.134037</td>\n",
       "      <td>9.206249</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.705707</td>\n",
       "      <td>0.724400</td>\n",
       "      <td>7.861056</td>\n",
       "      <td>17.189386</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.562428</td>\n",
       "      <td>0.782167</td>\n",
       "      <td>7.842278</td>\n",
       "      <td>25.155985</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.502012</td>\n",
       "      <td>0.810300</td>\n",
       "      <td>7.875513</td>\n",
       "      <td>33.154148</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.455699</td>\n",
       "      <td>0.833533</td>\n",
       "      <td>7.961695</td>\n",
       "      <td>41.239398</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch_duration  run duration    lr  \\\n",
       "0     1      1  1.017841  0.612950        7.645893      8.197881  0.01   \n",
       "1     1      2  0.521381  0.797317        7.493823     15.809482  0.01   \n",
       "2     1      3  0.420959  0.846900        7.524096     23.443556  0.01   \n",
       "3     1      4  0.376354  0.861817        7.458082     31.018337  0.01   \n",
       "4     1      5  0.343932  0.872367        7.551965     38.690419  0.01   \n",
       "5     2      1  0.901488  0.661833        8.522249      9.061235  0.01   \n",
       "6     2      2  0.465672  0.826367        8.366937     17.577125  0.01   \n",
       "7     2      3  0.386732  0.857750        8.584581     26.274714  0.01   \n",
       "8     2      4  0.351575  0.869317        8.387501     34.794836  0.01   \n",
       "9     2      5  0.328205  0.878800        8.313120     43.234395  0.01   \n",
       "10    3      1  1.277515  0.512050        8.508451      9.625108  0.01   \n",
       "11    3      2  0.674211  0.731617        8.462582     18.208171  0.01   \n",
       "12    3      3  0.584290  0.771167        8.500220     26.829895  0.01   \n",
       "13    3      4  0.522286  0.799667        8.523609     35.475895  0.01   \n",
       "14    3      5  0.469065  0.826067        8.506910     44.105716  0.01   \n",
       "15    4      1  1.280718  0.512583        8.134037      9.206249  0.01   \n",
       "16    4      2  0.705707  0.724400        7.861056     17.189386  0.01   \n",
       "17    4      3  0.562428  0.782167        7.842278     25.155985  0.01   \n",
       "18    4      4  0.502012  0.810300        7.875513     33.154148  0.01   \n",
       "19    4      5  0.455699  0.833533        7.961695     41.239398  0.01   \n",
       "\n",
       "    batch_size  shuffle  \n",
       "0         1000     True  \n",
       "1         1000     True  \n",
       "2         1000     True  \n",
       "3         1000     True  \n",
       "4         1000     True  \n",
       "5         1000    False  \n",
       "6         1000    False  \n",
       "7         1000    False  \n",
       "8         1000    False  \n",
       "9         1000    False  \n",
       "10        2000     True  \n",
       "11        2000     True  \n",
       "12        2000     True  \n",
       "13        2000     True  \n",
       "14        2000     True  \n",
       "15        2000    False  \n",
       "16        2000    False  \n",
       "17        2000    False  \n",
       "18        2000    False  \n",
       "19        2000    False  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01],\n",
    "    batch_size = [1000, 2000],\n",
    "    shuffle = [True, False]\n",
    ")\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    network = Network()\n",
    "    loader = DataLoader(train_set, batch_size=run.batch_size, shuffle=run.shuffle) \n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(5):\n",
    "        m.begin_epoch(epoch)\n",
    "\n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "\n",
    "m.save('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 34 DataLoader num_workers - Speed Limit Increase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.019271</td>\n",
       "      <td>0.605800</td>\n",
       "      <td>7.442017</td>\n",
       "      <td>7.997392</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944378</td>\n",
       "      <td>0.642233</td>\n",
       "      <td>6.439095</td>\n",
       "      <td>7.192991</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.011829</td>\n",
       "      <td>0.607883</td>\n",
       "      <td>3.713509</td>\n",
       "      <td>4.448341</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1.043159</td>\n",
       "      <td>0.589583</td>\n",
       "      <td>4.108103</td>\n",
       "      <td>4.917751</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1.057763</td>\n",
       "      <td>0.593317</td>\n",
       "      <td>4.104699</td>\n",
       "      <td>5.086607</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.318678</td>\n",
       "      <td>0.507533</td>\n",
       "      <td>8.413423</td>\n",
       "      <td>9.549574</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1.398434</td>\n",
       "      <td>0.463000</td>\n",
       "      <td>6.705700</td>\n",
       "      <td>8.063636</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1.380551</td>\n",
       "      <td>0.478533</td>\n",
       "      <td>4.442457</td>\n",
       "      <td>5.815802</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1.305490</td>\n",
       "      <td>0.494817</td>\n",
       "      <td>4.645245</td>\n",
       "      <td>6.101749</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1.269757</td>\n",
       "      <td>0.523850</td>\n",
       "      <td>4.509929</td>\n",
       "      <td>6.315699</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2000</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   run  epoch      loss  accuracy  epoch_duration  run duration    lr  \\\n",
       "0    1      1  1.019271  0.605800        7.442017      7.997392  0.01   \n",
       "1    2      1  0.944378  0.642233        6.439095      7.192991  0.01   \n",
       "2    3      1  1.011829  0.607883        3.713509      4.448341  0.01   \n",
       "3    4      1  1.043159  0.589583        4.108103      4.917751  0.01   \n",
       "4    5      1  1.057763  0.593317        4.104699      5.086607  0.01   \n",
       "5    6      1  1.318678  0.507533        8.413423      9.549574  0.01   \n",
       "6    7      1  1.398434  0.463000        6.705700      8.063636  0.01   \n",
       "7    8      1  1.380551  0.478533        4.442457      5.815802  0.01   \n",
       "8    9      1  1.305490  0.494817        4.645245      6.101749  0.01   \n",
       "9   10      1  1.269757  0.523850        4.509929      6.315699  0.01   \n",
       "\n",
       "   batch_size  num_workers  \n",
       "0        1000            0  \n",
       "1        1000            1  \n",
       "2        1000            2  \n",
       "3        1000            4  \n",
       "4        1000            8  \n",
       "5        2000            0  \n",
       "6        2000            1  \n",
       "7        2000            2  \n",
       "8        2000            4  \n",
       "9        2000            8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01],\n",
    "    batch_size = [1000, 2000],\n",
    "    num_workers = [0, 1, 2, 4, 8]\n",
    "    # shuffle = [True, False]\n",
    ")\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "\n",
    "    network = Network()\n",
    "    loader = DataLoader(train_set, batch_size=run.batch_size, num_workers=run.num_workers) \n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(1):\n",
    "        m.begin_epoch(epoch)\n",
    "\n",
    "        for batch in loader:\n",
    "            images, labels = batch\n",
    "\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "\n",
    "m.save('results')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 38 PyTorch Sequential Models - Neural Networks Made Easy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using nn.Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transform\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "torch.set_printoptions(linewidth=150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform.Compose([\n",
    "        transform.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "image, label = train_set[0]\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x77d3a8a57350>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(image.squeeze(), cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['T-shirt/top',\n",
       " 'Trouser',\n",
       " 'Pullover',\n",
       " 'Dress',\n",
       " 'Coat',\n",
       " 'Sandal',\n",
       " 'Shirt',\n",
       " 'Sneaker',\n",
       " 'Bag',\n",
       " 'Ankle boot']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_features = image.numel()\n",
    "in_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_features = math.floor(in_features/2)\n",
    "out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_classes = len(train_set.classes)\n",
    "out_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Flatten(start_dim=1, end_dim=-1)\n",
       "  (1): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (2): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network1 = nn.Sequential(\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features=in_features, out_features=out_features),\n",
    "    nn.Linear(in_features=out_features, out_features=out_classes),\n",
    ")\n",
    "\n",
    "network1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 28, 28])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = image.unsqueeze(0)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0553,  0.1830, -0.2657,  0.2325,  0.4462,  0.0778, -0.1540,  0.2891, -0.1754, -0.2128]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network1(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (hidden): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (output): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layers = OrderedDict([ \n",
    "    ('flat', nn.Flatten(start_dim=1)),\n",
    "    ('hidden', nn.Linear(in_features=in_features, out_features=out_features)),\n",
    "    ('output', nn.Linear(in_features=out_features, out_features=out_classes)),\n",
    "])\n",
    "\n",
    "network2 = nn.Sequential(layers)\n",
    "network2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1369, -0.0099,  0.2928,  0.0961, -0.0383, -0.1376,  0.0237,  0.0758, -0.2438,  0.0337]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network2(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "network1 = nn.Sequential(\n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features=in_features, out_features=out_features),\n",
    "    nn.Linear(in_features=out_features, out_features=out_classes),\n",
    ")\n",
    "\n",
    "torch.manual_seed(50)\n",
    "layers = OrderedDict([\n",
    "    ('flat', nn.Flatten(start_dim=1)),\n",
    "    ('hidden', nn.Linear(in_features=in_features, out_features=out_features)),\n",
    "    ('output', nn.Linear(in_features=out_features, out_features=out_classes)),\n",
    "])\n",
    "network2 = nn.Sequential(layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1681,  0.1028, -0.0790, -0.0659, -0.2436,  0.1328, -0.0864,  0.0016,  0.1819, -0.0168]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.1681,  0.1028, -0.0790, -0.0659, -0.2436,  0.1328, -0.0864,  0.0016,  0.1819, -0.0168]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network1(image), network2(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (flat): Flatten(start_dim=1, end_dim=-1)\n",
       "  (hidden): Linear(in_features=784, out_features=392, bias=True)\n",
       "  (output): Linear(in_features=392, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "network3 = nn.Sequential()\n",
    "\n",
    "network3.add_module('flat', nn.Flatten(start_dim=1))\n",
    "network3.add_module('hidden', nn.Linear(in_features=in_features, out_features=out_features))\n",
    "network3.add_module('output', nn.Linear(in_features=out_features, out_features=out_classes))\n",
    "network3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.1681,  0.1028, -0.0790, -0.0659, -0.2436,  0.1328, -0.0864,  0.0016,  0.1819, -0.0168]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.1681,  0.1028, -0.0790, -0.0659, -0.2436,  0.1328, -0.0864,  0.0016,  0.1819, -0.0168]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[ 0.1681,  0.1028, -0.0790, -0.0659, -0.2436,  0.1328, -0.0864,  0.0016,  0.1819, -0.0168]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network1(image), network2(image), network3(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a Network Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self): \n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
    "        self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
    "        self.out = nn.Linear(in_features=60, out_features=10)\n",
    "        \n",
    "    def forward(self, t):\n",
    "        t = F.relu(self.conv1(t))\n",
    "        t = F.max_pool2d(t, (2, 2), stride=2)\n",
    "\n",
    "        t = F.relu(self.conv2(t))\n",
    "        t = F.max_pool2d(t, (2, 2), stride=2)\n",
    "\n",
    "        t = t.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t = F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        \n",
    "        return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Network(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "\n",
    "network = Network()\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (1): ReLU()\n",
       "  (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (3): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (4): ReLU()\n",
       "  (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (6): Flatten(start_dim=1, end_dim=-1)\n",
       "  (7): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (8): ReLU()\n",
       "  (9): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (10): ReLU()\n",
       "  (11): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "\n",
    "sequential1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(12*4*4, 120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(120, 60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(60, 10)\n",
    ")\n",
    "sequential1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "layers = OrderedDict([\n",
    "    ('conv1', nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)),\n",
    "    ('relu1', nn.ReLU()),\n",
    "    ('pool1', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "\n",
    "    ('conv2', nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)),\n",
    "    ('relu2', nn.ReLU()),\n",
    "    ('pool2', nn.MaxPool2d(kernel_size=2, stride=2)),\n",
    "\n",
    "    ('flatten', nn.Flatten()),\n",
    "    ('fc1', nn.Linear(12*4*4, 120)),\n",
    "    ('relu3', nn.ReLU()),\n",
    "\n",
    "    ('fc2', nn.Linear(120, 60)),\n",
    "    ('relu4', nn.ReLU()),\n",
    "    ('out', nn.Linear(60, 10))\n",
    "])\n",
    "\n",
    "sequential2 = nn.Sequential(layers)\n",
    "sequential2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 12, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=192, out_features=120, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (fc2): Linear(in_features=120, out_features=60, bias=True)\n",
       "  (relu4): ReLU()\n",
       "  (out): Linear(in_features=60, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "\n",
    "sequential3 = nn.Sequential()\n",
    "\n",
    "sequential3.add_module('conv1', nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5))\n",
    "sequential3.add_module('relu1', nn.ReLU())\n",
    "sequential3.add_module('pool1', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "sequential3.add_module('conv2', nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5))\n",
    "sequential3.add_module('relu2', nn.ReLU())\n",
    "sequential3.add_module('pool2', nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "sequential3.add_module('flatten', nn.Flatten())\n",
    "sequential3.add_module('fc1', nn.Linear(12*4*4, 120))\n",
    "sequential3.add_module('relu3', nn.ReLU())\n",
    "\n",
    "sequential3.add_module('fc2', nn.Linear(120, 60))\n",
    "sequential3.add_module('relu4', nn.ReLU())\n",
    "sequential3.add_module('out', nn.Linear(60, 10))\n",
    "sequential3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0957,  0.1053, -0.1055,  0.1547, -0.0366, -0.0132,  0.0749, -0.1152,  0.0426,  0.0639]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.0957,  0.1053, -0.1055,  0.1547, -0.0366, -0.0132,  0.0749, -0.1152,  0.0426,  0.0639]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.0957,  0.1053, -0.1055,  0.1547, -0.0366, -0.0132,  0.0749, -0.1152,  0.0426,  0.0639]], grad_fn=<AddmmBackward0>),\n",
       " tensor([[-0.0957,  0.1053, -0.1055,  0.1547, -0.0366, -0.0132,  0.0749, -0.1152,  0.0426,  0.0639]], grad_fn=<AddmmBackward0>))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network(image), sequential1(image), sequential2(image), sequential3(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 39 Batch Norm in PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "network1 = nn.Sequential(\n",
    "    nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "    nn.ReLU(), \n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "    nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features=12*4*4, out_features=120),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=120, out_features=60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=60, out_features=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "network2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5),\n",
    "    nn.ReLU(), \n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    nn.BatchNorm2d(6),\n",
    "\n",
    "    nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5),\n",
    "    nn.ReLU(),\n",
    "    nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "    nn.Flatten(start_dim=1),\n",
    "    nn.Linear(in_features=12*4*4, out_features=120),\n",
    "    nn.ReLU(),\n",
    "    nn.BatchNorm1d(120),\n",
    "    nn.Linear(in_features=120, out_features=60),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(in_features=60, out_features=10)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform.Compose([\n",
    "        transform.ToTensor()\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.2860), tensor(0.3530))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "loader = DataLoader(train_set, batch_size=len(train_set), num_workers=1)\n",
    "data = next(iter(loader))\n",
    "mean = data[0].mean()\n",
    "std = data[0].std()\n",
    "\n",
    "mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set_normal = torchvision.datasets.FashionMNIST(\n",
    "    root='./data/FashionMNIST',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform.Compose([\n",
    "        transform.ToTensor(),\n",
    "        transform.Normalize(mean, std)\n",
    "    ])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsets = {\n",
    "    'not_normal': train_set,\n",
    "    'normal': train_set_normal\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "networks = {\n",
    "    'not_bn': network1,\n",
    "    'bn': network2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900740</td>\n",
       "      <td>0.666317</td>\n",
       "      <td>9.942994</td>\n",
       "      <td>10.691763</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.475423</td>\n",
       "      <td>0.820450</td>\n",
       "      <td>10.358734</td>\n",
       "      <td>21.193500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.395257</td>\n",
       "      <td>0.854767</td>\n",
       "      <td>9.458575</td>\n",
       "      <td>30.787357</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.352382</td>\n",
       "      <td>0.870583</td>\n",
       "      <td>9.111130</td>\n",
       "      <td>40.030115</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.323264</td>\n",
       "      <td>0.879917</td>\n",
       "      <td>9.271670</td>\n",
       "      <td>49.432677</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.306730</td>\n",
       "      <td>0.885967</td>\n",
       "      <td>9.706813</td>\n",
       "      <td>59.272423</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.294731</td>\n",
       "      <td>0.890233</td>\n",
       "      <td>9.378494</td>\n",
       "      <td>68.779393</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.283212</td>\n",
       "      <td>0.894417</td>\n",
       "      <td>9.187242</td>\n",
       "      <td>78.103576</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.280280</td>\n",
       "      <td>0.895350</td>\n",
       "      <td>9.013922</td>\n",
       "      <td>87.259170</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.271016</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>9.258216</td>\n",
       "      <td>96.657012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.260803</td>\n",
       "      <td>0.901817</td>\n",
       "      <td>9.483785</td>\n",
       "      <td>106.277374</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.252528</td>\n",
       "      <td>0.904417</td>\n",
       "      <td>8.815008</td>\n",
       "      <td>115.218237</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.246905</td>\n",
       "      <td>0.906633</td>\n",
       "      <td>9.913911</td>\n",
       "      <td>125.262539</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.243927</td>\n",
       "      <td>0.907283</td>\n",
       "      <td>10.248887</td>\n",
       "      <td>135.668213</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.235919</td>\n",
       "      <td>0.911633</td>\n",
       "      <td>9.161389</td>\n",
       "      <td>144.959124</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.230460</td>\n",
       "      <td>0.912850</td>\n",
       "      <td>9.477980</td>\n",
       "      <td>154.571393</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.230221</td>\n",
       "      <td>0.912200</td>\n",
       "      <td>8.933725</td>\n",
       "      <td>163.630906</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.235154</td>\n",
       "      <td>0.909583</td>\n",
       "      <td>8.877925</td>\n",
       "      <td>172.642488</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.233507</td>\n",
       "      <td>0.910833</td>\n",
       "      <td>9.253277</td>\n",
       "      <td>182.044971</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.221336</td>\n",
       "      <td>0.916750</td>\n",
       "      <td>9.462691</td>\n",
       "      <td>191.643265</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585110</td>\n",
       "      <td>0.787833</td>\n",
       "      <td>9.944156</td>\n",
       "      <td>10.654264</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.350514</td>\n",
       "      <td>0.869400</td>\n",
       "      <td>10.400357</td>\n",
       "      <td>21.249332</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.309323</td>\n",
       "      <td>0.884617</td>\n",
       "      <td>10.473257</td>\n",
       "      <td>31.876987</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.283958</td>\n",
       "      <td>0.893067</td>\n",
       "      <td>10.032476</td>\n",
       "      <td>42.075483</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.267240</td>\n",
       "      <td>0.899917</td>\n",
       "      <td>10.321645</td>\n",
       "      <td>52.546742</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.256786</td>\n",
       "      <td>0.903300</td>\n",
       "      <td>10.082151</td>\n",
       "      <td>62.792912</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.245320</td>\n",
       "      <td>0.907667</td>\n",
       "      <td>10.190617</td>\n",
       "      <td>73.147022</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.238538</td>\n",
       "      <td>0.909550</td>\n",
       "      <td>9.084603</td>\n",
       "      <td>82.383900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.225585</td>\n",
       "      <td>0.914483</td>\n",
       "      <td>9.604875</td>\n",
       "      <td>92.138737</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.217844</td>\n",
       "      <td>0.917450</td>\n",
       "      <td>10.028280</td>\n",
       "      <td>102.328400</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.209758</td>\n",
       "      <td>0.920117</td>\n",
       "      <td>10.191144</td>\n",
       "      <td>112.686450</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.205711</td>\n",
       "      <td>0.923533</td>\n",
       "      <td>10.025964</td>\n",
       "      <td>122.859605</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.206248</td>\n",
       "      <td>0.922183</td>\n",
       "      <td>9.846258</td>\n",
       "      <td>132.856063</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.194850</td>\n",
       "      <td>0.925967</td>\n",
       "      <td>9.476238</td>\n",
       "      <td>142.485161</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.193584</td>\n",
       "      <td>0.926967</td>\n",
       "      <td>9.271339</td>\n",
       "      <td>151.902706</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.188735</td>\n",
       "      <td>0.928017</td>\n",
       "      <td>9.098295</td>\n",
       "      <td>161.145195</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.183758</td>\n",
       "      <td>0.930800</td>\n",
       "      <td>9.743278</td>\n",
       "      <td>171.036256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.183944</td>\n",
       "      <td>0.929733</td>\n",
       "      <td>9.409281</td>\n",
       "      <td>180.599037</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.177439</td>\n",
       "      <td>0.931800</td>\n",
       "      <td>9.230963</td>\n",
       "      <td>189.982925</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.172350</td>\n",
       "      <td>0.934183</td>\n",
       "      <td>9.332448</td>\n",
       "      <td>199.501490</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch_duration  run duration    lr  \\\n",
       "0     1      1  0.900740  0.666317        9.942994     10.691763  0.01   \n",
       "1     1      2  0.475423  0.820450       10.358734     21.193500  0.01   \n",
       "2     1      3  0.395257  0.854767        9.458575     30.787357  0.01   \n",
       "3     1      4  0.352382  0.870583        9.111130     40.030115  0.01   \n",
       "4     1      5  0.323264  0.879917        9.271670     49.432677  0.01   \n",
       "5     1      6  0.306730  0.885967        9.706813     59.272423  0.01   \n",
       "6     1      7  0.294731  0.890233        9.378494     68.779393  0.01   \n",
       "7     1      8  0.283212  0.894417        9.187242     78.103576  0.01   \n",
       "8     1      9  0.280280  0.895350        9.013922     87.259170  0.01   \n",
       "9     1     10  0.271016  0.898333        9.258216     96.657012  0.01   \n",
       "10    1     11  0.260803  0.901817        9.483785    106.277374  0.01   \n",
       "11    1     12  0.252528  0.904417        8.815008    115.218237  0.01   \n",
       "12    1     13  0.246905  0.906633        9.913911    125.262539  0.01   \n",
       "13    1     14  0.243927  0.907283       10.248887    135.668213  0.01   \n",
       "14    1     15  0.235919  0.911633        9.161389    144.959124  0.01   \n",
       "15    1     16  0.230460  0.912850        9.477980    154.571393  0.01   \n",
       "16    1     17  0.230221  0.912200        8.933725    163.630906  0.01   \n",
       "17    1     18  0.235154  0.909583        8.877925    172.642488  0.01   \n",
       "18    1     19  0.233507  0.910833        9.253277    182.044971  0.01   \n",
       "19    1     20  0.221336  0.916750        9.462691    191.643265  0.01   \n",
       "20    2      1  0.585110  0.787833        9.944156     10.654264  0.01   \n",
       "21    2      2  0.350514  0.869400       10.400357     21.249332  0.01   \n",
       "22    2      3  0.309323  0.884617       10.473257     31.876987  0.01   \n",
       "23    2      4  0.283958  0.893067       10.032476     42.075483  0.01   \n",
       "24    2      5  0.267240  0.899917       10.321645     52.546742  0.01   \n",
       "25    2      6  0.256786  0.903300       10.082151     62.792912  0.01   \n",
       "26    2      7  0.245320  0.907667       10.190617     73.147022  0.01   \n",
       "27    2      8  0.238538  0.909550        9.084603     82.383900  0.01   \n",
       "28    2      9  0.225585  0.914483        9.604875     92.138737  0.01   \n",
       "29    2     10  0.217844  0.917450       10.028280    102.328400  0.01   \n",
       "30    2     11  0.209758  0.920117       10.191144    112.686450  0.01   \n",
       "31    2     12  0.205711  0.923533       10.025964    122.859605  0.01   \n",
       "32    2     13  0.206248  0.922183        9.846258    132.856063  0.01   \n",
       "33    2     14  0.194850  0.925967        9.476238    142.485161  0.01   \n",
       "34    2     15  0.193584  0.926967        9.271339    151.902706  0.01   \n",
       "35    2     16  0.188735  0.928017        9.098295    161.145195  0.01   \n",
       "36    2     17  0.183758  0.930800        9.743278    171.036256  0.01   \n",
       "37    2     18  0.183944  0.929733        9.409281    180.599037  0.01   \n",
       "38    2     19  0.177439  0.931800        9.230963    189.982925  0.01   \n",
       "39    2     20  0.172350  0.934183        9.332448    199.501490  0.01   \n",
       "\n",
       "    batch_size  num_workers device trainset network  \n",
       "0         1000            1    cpu   normal  not_bn  \n",
       "1         1000            1    cpu   normal  not_bn  \n",
       "2         1000            1    cpu   normal  not_bn  \n",
       "3         1000            1    cpu   normal  not_bn  \n",
       "4         1000            1    cpu   normal  not_bn  \n",
       "5         1000            1    cpu   normal  not_bn  \n",
       "6         1000            1    cpu   normal  not_bn  \n",
       "7         1000            1    cpu   normal  not_bn  \n",
       "8         1000            1    cpu   normal  not_bn  \n",
       "9         1000            1    cpu   normal  not_bn  \n",
       "10        1000            1    cpu   normal  not_bn  \n",
       "11        1000            1    cpu   normal  not_bn  \n",
       "12        1000            1    cpu   normal  not_bn  \n",
       "13        1000            1    cpu   normal  not_bn  \n",
       "14        1000            1    cpu   normal  not_bn  \n",
       "15        1000            1    cpu   normal  not_bn  \n",
       "16        1000            1    cpu   normal  not_bn  \n",
       "17        1000            1    cpu   normal  not_bn  \n",
       "18        1000            1    cpu   normal  not_bn  \n",
       "19        1000            1    cpu   normal  not_bn  \n",
       "20        1000            1    cpu   normal      bn  \n",
       "21        1000            1    cpu   normal      bn  \n",
       "22        1000            1    cpu   normal      bn  \n",
       "23        1000            1    cpu   normal      bn  \n",
       "24        1000            1    cpu   normal      bn  \n",
       "25        1000            1    cpu   normal      bn  \n",
       "26        1000            1    cpu   normal      bn  \n",
       "27        1000            1    cpu   normal      bn  \n",
       "28        1000            1    cpu   normal      bn  \n",
       "29        1000            1    cpu   normal      bn  \n",
       "30        1000            1    cpu   normal      bn  \n",
       "31        1000            1    cpu   normal      bn  \n",
       "32        1000            1    cpu   normal      bn  \n",
       "33        1000            1    cpu   normal      bn  \n",
       "34        1000            1    cpu   normal      bn  \n",
       "35        1000            1    cpu   normal      bn  \n",
       "36        1000            1    cpu   normal      bn  \n",
       "37        1000            1    cpu   normal      bn  \n",
       "38        1000            1    cpu   normal      bn  \n",
       "39        1000            1    cpu   normal      bn  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr = [.01],\n",
    "    batch_size = [1000],\n",
    "    num_workers = [1],\n",
    "    device = ['cpu'],\n",
    "    trainset = ['normal'],\n",
    "    network = list(networks.keys())\n",
    ")\n",
    "\n",
    "m = RunManager()\n",
    "\n",
    "for run in RunBuilder.get_runs(params):\n",
    "    device = torch.device(run.device)\n",
    "    network = networks[run.network].to(device)\n",
    "    \n",
    "    loader = DataLoader(trainsets[run.trainset], batch_size=run.batch_size, num_workers=run.num_workers) \n",
    "    optimizer = optim.Adam(network.parameters(), lr=run.lr)\n",
    "\n",
    "    m.begin_run(run, network, loader)\n",
    "    for epoch in range(20):\n",
    "        m.begin_epoch(epoch)\n",
    "\n",
    "        for batch in loader:\n",
    "            # images, labels = batch\n",
    "            images = batch[0].to(device)  # <---\n",
    "            labels = batch[1].to(device)  # <---\n",
    "\n",
    "            preds = network(images)\n",
    "            loss = F.cross_entropy(preds, labels)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds, labels)\n",
    "\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n",
    "\n",
    "m.save('results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>epoch</th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>epoch_duration</th>\n",
       "      <th>run duration</th>\n",
       "      <th>lr</th>\n",
       "      <th>batch_size</th>\n",
       "      <th>num_workers</th>\n",
       "      <th>device</th>\n",
       "      <th>trainset</th>\n",
       "      <th>network</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>0.172350</td>\n",
       "      <td>0.934183</td>\n",
       "      <td>9.332448</td>\n",
       "      <td>199.501490</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>0.177439</td>\n",
       "      <td>0.931800</td>\n",
       "      <td>9.230963</td>\n",
       "      <td>189.982925</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>0.183758</td>\n",
       "      <td>0.930800</td>\n",
       "      <td>9.743278</td>\n",
       "      <td>171.036256</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>0.183944</td>\n",
       "      <td>0.929733</td>\n",
       "      <td>9.409281</td>\n",
       "      <td>180.599037</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>0.188735</td>\n",
       "      <td>0.928017</td>\n",
       "      <td>9.098295</td>\n",
       "      <td>161.145195</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0.193584</td>\n",
       "      <td>0.926967</td>\n",
       "      <td>9.271339</td>\n",
       "      <td>151.902706</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>0.194850</td>\n",
       "      <td>0.925967</td>\n",
       "      <td>9.476238</td>\n",
       "      <td>142.485161</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.205711</td>\n",
       "      <td>0.923533</td>\n",
       "      <td>10.025964</td>\n",
       "      <td>122.859605</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.206248</td>\n",
       "      <td>0.922183</td>\n",
       "      <td>9.846258</td>\n",
       "      <td>132.856063</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>0.209758</td>\n",
       "      <td>0.920117</td>\n",
       "      <td>10.191144</td>\n",
       "      <td>112.686450</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>0.217844</td>\n",
       "      <td>0.917450</td>\n",
       "      <td>10.028280</td>\n",
       "      <td>102.328400</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0.221336</td>\n",
       "      <td>0.916750</td>\n",
       "      <td>9.462691</td>\n",
       "      <td>191.643265</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>0.225585</td>\n",
       "      <td>0.914483</td>\n",
       "      <td>9.604875</td>\n",
       "      <td>92.138737</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.230460</td>\n",
       "      <td>0.912850</td>\n",
       "      <td>9.477980</td>\n",
       "      <td>154.571393</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.230221</td>\n",
       "      <td>0.912200</td>\n",
       "      <td>8.933725</td>\n",
       "      <td>163.630906</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0.235919</td>\n",
       "      <td>0.911633</td>\n",
       "      <td>9.161389</td>\n",
       "      <td>144.959124</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>0.233507</td>\n",
       "      <td>0.910833</td>\n",
       "      <td>9.253277</td>\n",
       "      <td>182.044971</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0.235154</td>\n",
       "      <td>0.909583</td>\n",
       "      <td>8.877925</td>\n",
       "      <td>172.642488</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0.238538</td>\n",
       "      <td>0.909550</td>\n",
       "      <td>9.084603</td>\n",
       "      <td>82.383900</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.245320</td>\n",
       "      <td>0.907667</td>\n",
       "      <td>10.190617</td>\n",
       "      <td>73.147022</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0.243927</td>\n",
       "      <td>0.907283</td>\n",
       "      <td>10.248887</td>\n",
       "      <td>135.668213</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0.246905</td>\n",
       "      <td>0.906633</td>\n",
       "      <td>9.913911</td>\n",
       "      <td>125.262539</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.252528</td>\n",
       "      <td>0.904417</td>\n",
       "      <td>8.815008</td>\n",
       "      <td>115.218237</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0.256786</td>\n",
       "      <td>0.903300</td>\n",
       "      <td>10.082151</td>\n",
       "      <td>62.792912</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>0.260803</td>\n",
       "      <td>0.901817</td>\n",
       "      <td>9.483785</td>\n",
       "      <td>106.277374</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0.267240</td>\n",
       "      <td>0.899917</td>\n",
       "      <td>10.321645</td>\n",
       "      <td>52.546742</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.271016</td>\n",
       "      <td>0.898333</td>\n",
       "      <td>9.258216</td>\n",
       "      <td>96.657012</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0.280280</td>\n",
       "      <td>0.895350</td>\n",
       "      <td>9.013922</td>\n",
       "      <td>87.259170</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.283212</td>\n",
       "      <td>0.894417</td>\n",
       "      <td>9.187242</td>\n",
       "      <td>78.103576</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.283958</td>\n",
       "      <td>0.893067</td>\n",
       "      <td>10.032476</td>\n",
       "      <td>42.075483</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.294731</td>\n",
       "      <td>0.890233</td>\n",
       "      <td>9.378494</td>\n",
       "      <td>68.779393</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.306730</td>\n",
       "      <td>0.885967</td>\n",
       "      <td>9.706813</td>\n",
       "      <td>59.272423</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.309323</td>\n",
       "      <td>0.884617</td>\n",
       "      <td>10.473257</td>\n",
       "      <td>31.876987</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.323264</td>\n",
       "      <td>0.879917</td>\n",
       "      <td>9.271670</td>\n",
       "      <td>49.432677</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.352382</td>\n",
       "      <td>0.870583</td>\n",
       "      <td>9.111130</td>\n",
       "      <td>40.030115</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.350514</td>\n",
       "      <td>0.869400</td>\n",
       "      <td>10.400357</td>\n",
       "      <td>21.249332</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.395257</td>\n",
       "      <td>0.854767</td>\n",
       "      <td>9.458575</td>\n",
       "      <td>30.787357</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.475423</td>\n",
       "      <td>0.820450</td>\n",
       "      <td>10.358734</td>\n",
       "      <td>21.193500</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.585110</td>\n",
       "      <td>0.787833</td>\n",
       "      <td>9.944156</td>\n",
       "      <td>10.654264</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>bn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.900740</td>\n",
       "      <td>0.666317</td>\n",
       "      <td>9.942994</td>\n",
       "      <td>10.691763</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>cpu</td>\n",
       "      <td>normal</td>\n",
       "      <td>not_bn</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    run  epoch      loss  accuracy  epoch_duration  run duration    lr  \\\n",
       "39    2     20  0.172350  0.934183        9.332448    199.501490  0.01   \n",
       "38    2     19  0.177439  0.931800        9.230963    189.982925  0.01   \n",
       "36    2     17  0.183758  0.930800        9.743278    171.036256  0.01   \n",
       "37    2     18  0.183944  0.929733        9.409281    180.599037  0.01   \n",
       "35    2     16  0.188735  0.928017        9.098295    161.145195  0.01   \n",
       "34    2     15  0.193584  0.926967        9.271339    151.902706  0.01   \n",
       "33    2     14  0.194850  0.925967        9.476238    142.485161  0.01   \n",
       "31    2     12  0.205711  0.923533       10.025964    122.859605  0.01   \n",
       "32    2     13  0.206248  0.922183        9.846258    132.856063  0.01   \n",
       "30    2     11  0.209758  0.920117       10.191144    112.686450  0.01   \n",
       "29    2     10  0.217844  0.917450       10.028280    102.328400  0.01   \n",
       "19    1     20  0.221336  0.916750        9.462691    191.643265  0.01   \n",
       "28    2      9  0.225585  0.914483        9.604875     92.138737  0.01   \n",
       "15    1     16  0.230460  0.912850        9.477980    154.571393  0.01   \n",
       "16    1     17  0.230221  0.912200        8.933725    163.630906  0.01   \n",
       "14    1     15  0.235919  0.911633        9.161389    144.959124  0.01   \n",
       "18    1     19  0.233507  0.910833        9.253277    182.044971  0.01   \n",
       "17    1     18  0.235154  0.909583        8.877925    172.642488  0.01   \n",
       "27    2      8  0.238538  0.909550        9.084603     82.383900  0.01   \n",
       "26    2      7  0.245320  0.907667       10.190617     73.147022  0.01   \n",
       "13    1     14  0.243927  0.907283       10.248887    135.668213  0.01   \n",
       "12    1     13  0.246905  0.906633        9.913911    125.262539  0.01   \n",
       "11    1     12  0.252528  0.904417        8.815008    115.218237  0.01   \n",
       "25    2      6  0.256786  0.903300       10.082151     62.792912  0.01   \n",
       "10    1     11  0.260803  0.901817        9.483785    106.277374  0.01   \n",
       "24    2      5  0.267240  0.899917       10.321645     52.546742  0.01   \n",
       "9     1     10  0.271016  0.898333        9.258216     96.657012  0.01   \n",
       "8     1      9  0.280280  0.895350        9.013922     87.259170  0.01   \n",
       "7     1      8  0.283212  0.894417        9.187242     78.103576  0.01   \n",
       "23    2      4  0.283958  0.893067       10.032476     42.075483  0.01   \n",
       "6     1      7  0.294731  0.890233        9.378494     68.779393  0.01   \n",
       "5     1      6  0.306730  0.885967        9.706813     59.272423  0.01   \n",
       "22    2      3  0.309323  0.884617       10.473257     31.876987  0.01   \n",
       "4     1      5  0.323264  0.879917        9.271670     49.432677  0.01   \n",
       "3     1      4  0.352382  0.870583        9.111130     40.030115  0.01   \n",
       "21    2      2  0.350514  0.869400       10.400357     21.249332  0.01   \n",
       "2     1      3  0.395257  0.854767        9.458575     30.787357  0.01   \n",
       "1     1      2  0.475423  0.820450       10.358734     21.193500  0.01   \n",
       "20    2      1  0.585110  0.787833        9.944156     10.654264  0.01   \n",
       "0     1      1  0.900740  0.666317        9.942994     10.691763  0.01   \n",
       "\n",
       "    batch_size  num_workers device trainset network  \n",
       "39        1000            1    cpu   normal      bn  \n",
       "38        1000            1    cpu   normal      bn  \n",
       "36        1000            1    cpu   normal      bn  \n",
       "37        1000            1    cpu   normal      bn  \n",
       "35        1000            1    cpu   normal      bn  \n",
       "34        1000            1    cpu   normal      bn  \n",
       "33        1000            1    cpu   normal      bn  \n",
       "31        1000            1    cpu   normal      bn  \n",
       "32        1000            1    cpu   normal      bn  \n",
       "30        1000            1    cpu   normal      bn  \n",
       "29        1000            1    cpu   normal      bn  \n",
       "19        1000            1    cpu   normal  not_bn  \n",
       "28        1000            1    cpu   normal      bn  \n",
       "15        1000            1    cpu   normal  not_bn  \n",
       "16        1000            1    cpu   normal  not_bn  \n",
       "14        1000            1    cpu   normal  not_bn  \n",
       "18        1000            1    cpu   normal  not_bn  \n",
       "17        1000            1    cpu   normal  not_bn  \n",
       "27        1000            1    cpu   normal      bn  \n",
       "26        1000            1    cpu   normal      bn  \n",
       "13        1000            1    cpu   normal  not_bn  \n",
       "12        1000            1    cpu   normal  not_bn  \n",
       "11        1000            1    cpu   normal  not_bn  \n",
       "25        1000            1    cpu   normal      bn  \n",
       "10        1000            1    cpu   normal  not_bn  \n",
       "24        1000            1    cpu   normal      bn  \n",
       "9         1000            1    cpu   normal  not_bn  \n",
       "8         1000            1    cpu   normal  not_bn  \n",
       "7         1000            1    cpu   normal  not_bn  \n",
       "23        1000            1    cpu   normal      bn  \n",
       "6         1000            1    cpu   normal  not_bn  \n",
       "5         1000            1    cpu   normal  not_bn  \n",
       "22        1000            1    cpu   normal      bn  \n",
       "4         1000            1    cpu   normal  not_bn  \n",
       "3         1000            1    cpu   normal  not_bn  \n",
       "21        1000            1    cpu   normal      bn  \n",
       "2         1000            1    cpu   normal  not_bn  \n",
       "1         1000            1    cpu   normal  not_bn  \n",
       "20        1000            1    cpu   normal      bn  \n",
       "0         1000            1    cpu   normal  not_bn  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(m.run_data, orient='columns' ).sort_values(\"accuracy\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 40 Reset Weights PyTorch Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1669, -0.6100]], requires_grad=True)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "layer = nn.Linear(2,1)\n",
    "layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = torch.rand(2)\n",
    "o = layer(t)\n",
    "o.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(layer.parameters(), lr=0.01)\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1569, -0.6200]], requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1669, -0.6100]], requires_grad=True)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "layer.reset_parameters()\n",
    "layer.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Individual layer inside a network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2, out_features=1, bias=True)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(2,1)\n",
    ")\n",
    "network[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1669, -0.6100]], requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1569, -0.6200]], requires_grad=True)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2)\n",
    "o = network(t)\n",
    "o.backward()\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "optimizer.step()\n",
    "network[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1669, -0.6100]], requires_grad=True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "network[0].reset_parameters()\n",
    "network[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of layers inside a network\n",
    "\n",
    "Use method above to target each layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All weights layer by layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.6500, -0.1395]], requires_grad=True)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nn.Sequential(\n",
    "    nn.Linear(2,1)\n",
    ")\n",
    "\n",
    "network[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "for module in network.children():\n",
    "    module.reset_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1669, -0.6100]], requires_grad=True)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=2, out_features=1, bias=True)\n",
       "  (1): Softmax(dim=None)\n",
       ")"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network = nn.Sequential(\n",
    "    nn.Linear(2,1),\n",
    "    nn.Softmax()\n",
    ")\n",
    "network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Softmax' object has no attribute 'reset_parameters'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    torch.manual_seed(50)\n",
    "    for module in network.children():\n",
    "        module.reset_parameters()\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All Weights using snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(50)\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(2,1)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1669, -0.6100]], requires_grad=True)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(network.state_dict(), './network.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1569, -0.6200]], requires_grad=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2)\n",
    "o = network(t)\n",
    "o.backward()\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "optimizer.step()\n",
    "network[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2233320/1984424774.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load('./network.pt')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OrderedDict([('0.weight', tensor([[ 0.1669, -0.6100]])),\n",
       "             ('0.bias', tensor([-0.1566]))])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('./network.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2233320/1006897256.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  network.load_state_dict(torch.load('./network.pt'))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network.load_state_dict(torch.load('./network.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1669, -0.6100]], requires_grad=True)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network[0].weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All weights using re-initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1669, -0.6100]], requires_grad=True)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(2,1)\n",
    ")\n",
    "\n",
    "network[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1569, -0.6200]], requires_grad=True)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.rand(2)\n",
    "o = network(t)\n",
    "o.backward()\n",
    "\n",
    "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
    "optimizer.step()\n",
    "network[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.1669, -0.6100]], requires_grad=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(50)\n",
    "network = nn.Sequential(\n",
    "    nn.Linear(2,1)\n",
    ")\n",
    "\n",
    "network[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Running TensorBoard in Colab + GPU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
